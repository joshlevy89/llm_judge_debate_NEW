{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eae7cec",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f782f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "from utils.analysis2_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ab5b9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/xmd1jn1s1gg47vfyv_n8g3xh0000gn/T/ipykernel_34348/3362829089.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat(dfs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def load_all_records_into_df(type):\n",
    "    # Get all the verdict file names in the results/verdicts folder\n",
    "    verdict_files = glob.glob(f'results/{type}/*.jsonl')\n",
    "\n",
    "    # Load each verdict file into a dataframe\n",
    "    dfs = []\n",
    "    for file in verdict_files:\n",
    "        df = pd.read_json(file, lines=True)\n",
    "        if df.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # expand config\n",
    "        config_df = pd.json_normalize(df['config'])\n",
    "        config_df.columns = ['config_' + col for col in config_df.columns]\n",
    "        df = pd.concat([df, config_df], axis=1)\n",
    "\n",
    "        # make an option_str\n",
    "        df['options_str'] = df['options'].apply(str)\n",
    "\n",
    "        # put the type as suffix for every column\n",
    "        df.columns = [col + '_' + type for col in df.columns]\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concatenate all the dataframes into one\n",
    "    df = pd.concat(dfs)\n",
    "    return df\n",
    "\n",
    "# Get all the records\n",
    "verdict_df = load_all_records_into_df('verdicts')\n",
    "debate_df = load_all_records_into_df('debates')\n",
    "qa_df = load_all_records_into_df('qa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb10d580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['run_id_qa', 'datetime_qa', 'config_qa', 'question_idx_qa',\n",
       "       'question_qa', 'options_qa', 'correct_idx_qa', 'raw_model_response_qa',\n",
       "       'parsed_model_response_qa', 'prompt_qa', 'token_usage_qa',\n",
       "       'record_id_qa', 'prompt_template_qa', 'internal_model_reasoning_qa',\n",
       "       'internal_model_reasoning_details_qa', 'success_qa', 'error_message_qa',\n",
       "       'config_dataset_name_qa', 'config_dataset_subset_qa',\n",
       "       'config_dataset_split_qa', 'config_model_name_qa',\n",
       "       'config_temperature_qa', 'config_num_questions_qa',\n",
       "       'config_random_seed_qa', 'config_num_choices_qa',\n",
       "       'config_max_threads_qa', 'config_specific_question_idxs_qa',\n",
       "       'config_rerun_qa', 'options_str_qa'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baacab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "75ebae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge them.\n",
    "\n",
    "verdict_and_debate_df = verdict_df.merge(debate_df, left_on=['record_id_verdicts'], right_on=['record_id_debates'], how='left')\n",
    "\n",
    "judge_qa_df = qa_df.copy()\n",
    "judge_qa_df.columns = [col + '_judge' for col in qa_df.columns]\n",
    "\n",
    "debater_qa_df = qa_df.copy()\n",
    "debater_qa_df.columns = [col + '_debater' for col in qa_df.columns]\n",
    "\n",
    "\n",
    "all_df = verdict_and_debate_df.merge(\n",
    "    judge_qa_df[['question_qa_judge', 'options_str_qa_judge', 'config_model_name_qa_judge', 'parsed_model_response_qa_judge', 'success_qa_judge']], \n",
    "    left_on=['question_verdicts', 'options_str_verdicts', 'config_judge_model_verdicts'], \n",
    "    right_on=['question_qa_judge', 'options_str_qa_judge', 'config_model_name_qa_judge'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "all_df = all_df.merge(\n",
    "    debater_qa_df[['question_qa_debater', 'options_str_qa_debater', 'config_model_name_qa_debater', 'parsed_model_response_qa_debater', 'success_qa_debater']], \n",
    "    left_on=['question_verdicts', 'options_str_verdicts', 'config_debater_model_debates'], \n",
    "    right_on=['question_qa_debater', 'options_str_qa_debater', 'config_model_name_qa_debater'],\n",
    "    how='left',\n",
    "    suffixes=('', '_debater')\n",
    ")\n",
    "\n",
    "# # Filter by success\n",
    "# all_df = all_df[all_df['success_verdicts'] & (all_df['success_debates'] == True) & (all_df['success_qa_judge'] == True) & (all_df['success_qa_debater'] == True)]\n",
    "\n",
    "# Get and filter by answer\n",
    "# all_df['parsed_answer_qa_judge'] = all_df['parsed_model_response_qa_judge'].apply(lambda x: x.get('answer', None))\n",
    "all_df['parsed_answer_qa_judge'] = all_df['parsed_model_response_qa_judge'].apply(lambda x: x.get('answer') if pd.notna(x) else None)\n",
    "all_df['parsed_answer_qa_debater'] = all_df['parsed_model_response_qa_debater'].apply(lambda x: x.get('answer') if pd.notna(x) else None)\n",
    "all_df['parsed_answer_verdicts'] = all_df['judge_verdict_verdicts'].apply(lambda x: x.get('parsed', {}).get('answer') if pd.notna(x) and isinstance(x, dict) else None)\n",
    "all_df = all_df[all_df['parsed_answer_qa_judge'].notnull() & all_df['parsed_answer_qa_debater'].notnull() & all_df['parsed_answer_verdicts'].notnull()]\n",
    "\n",
    "# Add the correct columns\n",
    "all_df['is_correct_qa_judge'] = all_df['parsed_answer_qa_judge'] == all_df['correct_idx_verdicts']\n",
    "all_df['is_correct_qa_debater'] = all_df['parsed_answer_qa_debater'] == all_df['correct_idx_verdicts']\n",
    "all_df['is_correct_verdict'] = all_df['parsed_answer_verdicts'] == all_df['correct_idx_verdicts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33069c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dedupe them\n",
    "\n",
    "dedupe_columns = [\n",
    "    \"record_id_verdicts\",\n",
    "    \"config_debate_run_id_verdicts\",\n",
    "    \"config_dataset_name_debates\", \n",
    "    \"config_dataset_subset_debates\", \n",
    "    \"config_dataset_split_debates\", \n",
    "    \"config_debater_model_debates\", \n",
    "    \"config_debater_temperature_debates\", \n",
    "    \"config_random_seed_debates\", \n",
    "    \"config_num_choices_debates\", \n",
    "    \"config_num_turns_debates\", \n",
    "    # \"config_private_scratchpad_debates\",\n",
    "    \"config_public_argument_word_limit_debates\",\n",
    "    # \"config_private_reasoning_word_limit_debates\",\n",
    "    \"config_judge_model_verdicts\", \n",
    "    \"config_judge_temperature_verdicts\", \n",
    "    \"config_max_output_tokens_verdicts\"\n",
    "]\n",
    "\n",
    "unique_df = all_df.sort_values('datetime_verdicts').drop_duplicates(subset=dedupe_columns, keep='last')\n",
    "\n",
    "\n",
    "# unique_configs = unique_df[dedupe_columns].to_dict('records')\n",
    "# pd.DataFrame(unique_configs).reset_index().rename(columns={'index': 'unique_config_id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "97f39bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to just what want to work with\n",
    "\n",
    "config_filter = {\n",
    "    'config_dataset_name_debates': 'Idavidrein/gpqa',\n",
    "    'config_dataset_subset_debates': 'gpqa_diamond',\n",
    "    'config_dataset_split_debates': 'train',\n",
    "    'config_random_seed_debates': 42,\n",
    "    'config_num_turns_debates': 1,\n",
    "    'config_private_scratchpad_debates': False,\n",
    "    'config_public_argument_word_limit_debates': 200,\n",
    "    'config_judge_temperature_verdicts': 0.0,\n",
    "}\n",
    "\n",
    "\n",
    "mask = (unique_df[list(config_filter)]\n",
    "        == pd.Series(config_filter)).all(axis=1)\n",
    "\n",
    "df = unique_df[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a09e5f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config_num_choices_debates\n",
       "2.0    2484\n",
       "4.0    1601\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_df[unique_df['config_judge_model_verdicts'] == 'openai/gpt-4o-mini']['config_num_choices_debates'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6d21acc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/xmd1jn1s1gg47vfyv_n8g3xh0000gn/T/ipykernel_34348/1827494867.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  unique_df[(unique_df['config_judge_model_verdicts'] == 'openai/gpt-4o-mini') & (df['config_num_choices_debates'] == 2)]['verdict_run_id_verdicts'].value_counts()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "verdict_run_id_verdicts\n",
       "k26y5y6    192\n",
       "uh2gayc    190\n",
       "qwf1c51      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_df[(unique_df['config_judge_model_verdicts'] == 'openai/gpt-4o-mini') & (df['config_num_choices_debates'] == 2)]['verdict_run_id_verdicts'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9570ba6f",
   "metadata": {},
   "source": [
    "### Analyze accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1b052e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>debater_qa_acc</th>\n",
       "      <th>judge_qa_acc</th>\n",
       "      <th>verdict_acc</th>\n",
       "      <th>debater_qa_n_correct</th>\n",
       "      <th>judge_qa_n_correct</th>\n",
       "      <th>verdict_n_correct</th>\n",
       "      <th>n_total</th>\n",
       "      <th>verdict_minus_judge_qa</th>\n",
       "      <th>pgr</th>\n",
       "      <th>debater_minus_judge_qa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google/gemma-3-12b-it</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.588571</td>\n",
       "      <td>0.588571</td>\n",
       "      <td>160</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google/gemma-3-27b-it</td>\n",
       "      <td>0.937173</td>\n",
       "      <td>0.638743</td>\n",
       "      <td>0.654450</td>\n",
       "      <td>179</td>\n",
       "      <td>122</td>\n",
       "      <td>125</td>\n",
       "      <td>191</td>\n",
       "      <td>0.015707</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.298429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meta-llama/llama-3-8b-instruct</td>\n",
       "      <td>0.922652</td>\n",
       "      <td>0.524862</td>\n",
       "      <td>0.491713</td>\n",
       "      <td>167</td>\n",
       "      <td>95</td>\n",
       "      <td>89</td>\n",
       "      <td>181</td>\n",
       "      <td>-0.033149</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.397790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meta-llama/llama-3.1-405b-instruct</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.635417</td>\n",
       "      <td>178</td>\n",
       "      <td>135</td>\n",
       "      <td>122</td>\n",
       "      <td>192</td>\n",
       "      <td>-0.067708</td>\n",
       "      <td>-0.302326</td>\n",
       "      <td>0.223958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meta-llama/llama-3.1-70b-instruct</td>\n",
       "      <td>0.913978</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>170</td>\n",
       "      <td>120</td>\n",
       "      <td>118</td>\n",
       "      <td>186</td>\n",
       "      <td>-0.010753</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>0.268817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>meta-llama/llama-3.1-8b-instruct</td>\n",
       "      <td>0.932886</td>\n",
       "      <td>0.530201</td>\n",
       "      <td>0.483221</td>\n",
       "      <td>139</td>\n",
       "      <td>79</td>\n",
       "      <td>72</td>\n",
       "      <td>149</td>\n",
       "      <td>-0.046980</td>\n",
       "      <td>-0.116667</td>\n",
       "      <td>0.402685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>meta-llama/llama-3.3-70b-instruct</td>\n",
       "      <td>0.939891</td>\n",
       "      <td>0.699454</td>\n",
       "      <td>0.715847</td>\n",
       "      <td>172</td>\n",
       "      <td>128</td>\n",
       "      <td>131</td>\n",
       "      <td>183</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.240437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>meta-llama/llama-4-maverick</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.817460</td>\n",
       "      <td>0.817460</td>\n",
       "      <td>115</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>meta-llama/llama-4-scout</td>\n",
       "      <td>0.937143</td>\n",
       "      <td>0.697143</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>164</td>\n",
       "      <td>122</td>\n",
       "      <td>126</td>\n",
       "      <td>175</td>\n",
       "      <td>0.022857</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>openai/gpt-3.5-turbo</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.492063</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>175</td>\n",
       "      <td>93</td>\n",
       "      <td>84</td>\n",
       "      <td>189</td>\n",
       "      <td>-0.047619</td>\n",
       "      <td>-0.109756</td>\n",
       "      <td>0.433862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>openai/gpt-4o-mini</td>\n",
       "      <td>0.921671</td>\n",
       "      <td>0.566580</td>\n",
       "      <td>0.736292</td>\n",
       "      <td>353</td>\n",
       "      <td>217</td>\n",
       "      <td>282</td>\n",
       "      <td>383</td>\n",
       "      <td>0.169713</td>\n",
       "      <td>0.477941</td>\n",
       "      <td>0.355091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>qwen/qwen-2.5-72b-instruct</td>\n",
       "      <td>0.917098</td>\n",
       "      <td>0.658031</td>\n",
       "      <td>0.725389</td>\n",
       "      <td>177</td>\n",
       "      <td>127</td>\n",
       "      <td>140</td>\n",
       "      <td>193</td>\n",
       "      <td>0.067358</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.259067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>qwen/qwen-2.5-7b-instruct</td>\n",
       "      <td>0.940860</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.591398</td>\n",
       "      <td>175</td>\n",
       "      <td>92</td>\n",
       "      <td>110</td>\n",
       "      <td>186</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.216867</td>\n",
       "      <td>0.446237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>qwen/qwen3-14b</td>\n",
       "      <td>0.924419</td>\n",
       "      <td>0.773256</td>\n",
       "      <td>0.831395</td>\n",
       "      <td>159</td>\n",
       "      <td>133</td>\n",
       "      <td>143</td>\n",
       "      <td>172</td>\n",
       "      <td>0.058140</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.151163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>qwen/qwen3-235b-a22b</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>70</td>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.103896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>qwen/qwen3-32b</td>\n",
       "      <td>0.917722</td>\n",
       "      <td>0.803797</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>145</td>\n",
       "      <td>127</td>\n",
       "      <td>138</td>\n",
       "      <td>158</td>\n",
       "      <td>0.069620</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.113924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>qwen/qwen3-8b</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>69</td>\n",
       "      <td>63</td>\n",
       "      <td>64</td>\n",
       "      <td>74</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.081081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  debater_qa_acc  judge_qa_acc  \\\n",
       "0                google/gemma-3-12b-it        0.914286      0.588571   \n",
       "1                google/gemma-3-27b-it        0.937173      0.638743   \n",
       "2       meta-llama/llama-3-8b-instruct        0.922652      0.524862   \n",
       "3   meta-llama/llama-3.1-405b-instruct        0.927083      0.703125   \n",
       "4    meta-llama/llama-3.1-70b-instruct        0.913978      0.645161   \n",
       "5     meta-llama/llama-3.1-8b-instruct        0.932886      0.530201   \n",
       "6    meta-llama/llama-3.3-70b-instruct        0.939891      0.699454   \n",
       "7          meta-llama/llama-4-maverick        0.912698      0.817460   \n",
       "8             meta-llama/llama-4-scout        0.937143      0.697143   \n",
       "9                 openai/gpt-3.5-turbo        0.925926      0.492063   \n",
       "10                  openai/gpt-4o-mini        0.921671      0.566580   \n",
       "11          qwen/qwen-2.5-72b-instruct        0.917098      0.658031   \n",
       "12           qwen/qwen-2.5-7b-instruct        0.940860      0.494624   \n",
       "13                      qwen/qwen3-14b        0.924419      0.773256   \n",
       "14                qwen/qwen3-235b-a22b        0.909091      0.805195   \n",
       "15                      qwen/qwen3-32b        0.917722      0.803797   \n",
       "16                       qwen/qwen3-8b        0.932432      0.851351   \n",
       "\n",
       "    verdict_acc  debater_qa_n_correct  judge_qa_n_correct  verdict_n_correct  \\\n",
       "0      0.588571                   160                 103                103   \n",
       "1      0.654450                   179                 122                125   \n",
       "2      0.491713                   167                  95                 89   \n",
       "3      0.635417                   178                 135                122   \n",
       "4      0.634409                   170                 120                118   \n",
       "5      0.483221                   139                  79                 72   \n",
       "6      0.715847                   172                 128                131   \n",
       "7      0.817460                   115                 103                103   \n",
       "8      0.720000                   164                 122                126   \n",
       "9      0.444444                   175                  93                 84   \n",
       "10     0.736292                   353                 217                282   \n",
       "11     0.725389                   177                 127                140   \n",
       "12     0.591398                   175                  92                110   \n",
       "13     0.831395                   159                 133                143   \n",
       "14     0.844156                    70                  62                 65   \n",
       "15     0.873418                   145                 127                138   \n",
       "16     0.864865                    69                  63                 64   \n",
       "\n",
       "    n_total  verdict_minus_judge_qa       pgr  debater_minus_judge_qa  \n",
       "0       175                0.000000  0.000000                0.325714  \n",
       "1       191                0.015707  0.052632                0.298429  \n",
       "2       181               -0.033149 -0.083333                0.397790  \n",
       "3       192               -0.067708 -0.302326                0.223958  \n",
       "4       186               -0.010753 -0.040000                0.268817  \n",
       "5       149               -0.046980 -0.116667                0.402685  \n",
       "6       183                0.016393  0.068182                0.240437  \n",
       "7       126                0.000000  0.000000                0.095238  \n",
       "8       175                0.022857  0.095238                0.240000  \n",
       "9       189               -0.047619 -0.109756                0.433862  \n",
       "10      383                0.169713  0.477941                0.355091  \n",
       "11      193                0.067358  0.260000                0.259067  \n",
       "12      186                0.096774  0.216867                0.446237  \n",
       "13      172                0.058140  0.384615                0.151163  \n",
       "14       77                0.038961  0.375000                0.103896  \n",
       "15      158                0.069620  0.611111                0.113924  \n",
       "16       74                0.013514  0.166667                0.081081  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df = aggregate_by_fields(df[df['config_num_choices_debates'] == 2], ['config_judge_model_verdicts'])\n",
    "\n",
    "acc_df\n",
    "\n",
    "# from utils.analysis_utils import *\n",
    "# plot_results_by_name(acc_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_judge_debate_NEW_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
